#   Copyright 2021 Google LLC
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
steps:
  # - name: gcr.io/cloud-builders/git
  #   args:
  #     [
  #       "clone",
  #       "https://source.developers.google.com/p/$PROJECT_ID/r/$REPO_NAME",
  #     ]
  #   id: "check-out-source-code"

  # - name: gcr.io/cloud-builders/mvn:3.5.0-jdk-8
  #   args: ["package", "-q"]
  #   dir: "./data-processing-code"
  #   id: "build-jar"


  ################################
  ######## CI DATAFLOW  ##########
  ################################


  ######### TODO : ADD TESTS
  
  # - id: 'Unit testing'
  #   name: python:3.7-slim-stretch
  #   dir: python
  #   args: ["./run_unit_tests.sh"]

  - id: "Build the container image"
    name: "gcr.io/cloud-builders/docker"
    args: ["build", "-t", "gcr.io/${PROJECT_ID}/${_IMAGE_NAME}:${_IMAGE_TAG}", "-f", source-code/${_PIPELINE_NAME}.dockerfile", "source-code"]

  - id: "Push the container image"
    name: "gcr.io/cloud-builders/docker"
    args: ["push", "gcr.io/${PROJECT_ID}/${_IMAGE_NAME}:${_IMAGE_TAG}"]

  - id: 'Build dataflow template'
    name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'gcloud'
    args: [ 
      'dataflow', 
      'flex-template', 
      'build',
      '${_TEMPLATE_GCS_LOCATION}',
      '--image=gcr.io/${PROJECT_ID}/${_IMAGE_NAME}:${_IMAGE_TAG}',
      '--sdk-language=PYTHON', 
      '--metadata-file=source-code/template_spec/${_PIPELINE_NAME}_metadata.json'
    ]

    ######## TODO ADD INTEGRATION TEST

    # - id: 'System integration test'
    # name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    # entrypoint: 'bash'
    # env:
    #   - 'TEMPLATE_GCS_LOCATION=${_TEMPLATE_GCS_LOCATION}'
    #   - 'GCP_PROJECT=${PROJECT_ID}'
    #   - 'REGION=${_REGION}'
    #   - 'SETUP_FILE=/dataflow/template/data_pipeline/setup.py'
    # args: ["./run_system_integration_test.sh"]

# 

  # - name: gcr.io/cloud-builders/gsutil
  #   args:
  #     [
  #       "cp",
  #       "*bundled*.jar",
  #       "gs://${_DATAFLOW_JAR_BUCKET}/dataflow_deployment_$BUILD_ID.jar",
  #     ]
  #   dir: "./data-processing-code/target"
  #   id: "deploy-jar"

  ################################
  ######## CI COMPOSER ###########
  ################################

  ## TODO : Make test on operator code
  # - name: "gcr.io/cloud-solutions-images/apache-airflow:1.10"
  #   entrypoint: "python"
  #   args: ["test_compare_xcom_maps.py"]
  #   dir: "./workflow-dag"
  #   id: "unit-test-on-operator-code"


  ## TODO ADD COMPOSER CI

  # - name: gcr.io/cloud-builders/gsutil
  #   args: ["cp", "*", "gs://${_COMPOSER_INPUT_BUCKET}"]
  #   dir: "../data"
  #   id: "deploy-test-input-file"

  # - name: gcr.io/cloud-builders/gsutil
  #   args: ["cp", "graph_drug_mention.json", "gs://${_COMPOSER_REF_BUCKET}"]
  #   dir: "../result_json"
  #   id: "deploy-test-ref-file"

  # - name: gcr.io/cloud-builders/gcloud
  #   args:
  #     [
  #       "composer",
  #       "environments",
  #       "run",
  #       "${_COMPOSER_ENV_NAME}",
  #       "--location",
  #       "${_COMPOSER_REGION}",
  #       "variables",
  #       "--",
  #       "--set",
  #       "dataflow_jar_file_test",
  #       "dataflow_deployment_$BUILD_ID.jar",
  #     ]
  #   id: "set-composer-jar-ref"

  # - name: gcr.io/cloud-builders/gsutil
  #   args: ["cp", "compare_xcom_maps.py", "${_COMPOSER_DAG_BUCKET}"]
  #   dir: "./workflow-dag"
  #   id: "deploy-custom-operator"


  # - name: gcr.io/cloud-builders/gsutil
  #   args: ["cp", "data-pipeline-test.py", "${_COMPOSER_DAG_BUCKET}"]
  #   dir: "./workflow-dag"
  #   id: "deploy-processing-pipeline"


  # - name: gcr.io/cloud-builders/gcloud
  #   entrypoint: "bash"
  #   args:
  #     [
  #       "wait_for_dag_deployed.sh",
  #       "${_COMPOSER_ENV_NAME}",
  #       "${_COMPOSER_REGION}",
  #       "${_COMPOSER_DAG_NAME_TEST}",
  #       "6",
  #       "20",
  #     ]
  #   id: "wait-for-dag-deployed-on-composer"


  # - name: gcr.io/cloud-builders/gcloud
  #   args:
  #     [
  #       "composer",
  #       "environments",
  #       "run",
  #       "${_COMPOSER_ENV_NAME}",
  #       "--location",
  #       "${_COMPOSER_REGION}",
  #       "trigger_dag",
  #       "--",
  #       "${_COMPOSER_DAG_NAME_TEST}",
  #       "--run_id=$BUILD_ID",
  #     ]
  #   id: "trigger-pipeline-execution"


# To allow time for integration testing
timeout: 1800s